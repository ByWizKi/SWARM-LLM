import { NextRequest, NextResponse } from "next/server";
import { getServerSession } from "next-auth";
import { authOptions } from "@/app/api/auth/[...nextauth]/route";
import { AIAssistantInstructions } from "@/lib/rta-rules";

/**
 * API Route pour obtenir des recommandations de draft depuis un LLM
 *
 * Cette route re√ßoit l'√©tat actuel du draft et retourne des recommandations
 * bas√©es sur l'analyse strat√©gique (synergies, contre-picks, win conditions, etc.)
 */

interface DraftRecommendationRequest {
  playerAPicks: number[];
  playerBPicks: number[];
  playerABans?: number[];
  playerBBans?: number[];
  currentPhase: "picking" | "banning" | "completed";
  currentTurn: number;
  firstPlayer: "A" | "B";
}

export async function POST(request: NextRequest) {
  try {
    // V√©rifier l'authentification
    const session = await getServerSession(authOptions);
    if (!session) {
      return NextResponse.json(
        { error: "Non authentifi√©" },
        { status: 401 }
      );
    }

    const body: DraftRecommendationRequest = await request.json();
    const { playerAPicks, playerBPicks, playerABans = [], playerBBans = [], currentPhase, currentTurn, firstPlayer } = body;

    // Valider les donn√©es
    if (!Array.isArray(playerAPicks) || !Array.isArray(playerBPicks)) {
      return NextResponse.json(
        { error: "Format de donn√©es invalide" },
        { status: 400 }
      );
    }

    // Construire le prompt pour le LLM
    const draftContext = `
√âtat actuel du draft RTA :

- Phase: ${currentPhase}
- Tour: ${currentTurn + 1}
- Premier joueur: ${firstPlayer}
- Picks Joueur A (Vous): ${playerAPicks.length}/5 - [${playerAPicks.join(", ")}]
- Picks Joueur B (Adversaire): ${playerBPicks.length}/5 - [${playerBPicks.join(", ")}]
- Monstres d√©j√† s√©lectionn√©s: [${[...playerAPicks, ...playerBPicks].join(", ")}]

${currentPhase === "banning" ? `
- Phase de bans en cours
- Bans Joueur A: ${playerABans.length > 0 ? `[${playerABans.join(", ")}]` : "Pas encore banni"}
- Bans Joueur B: ${playerBBans.length > 0 ? `[${playerBBans.join(", ")}]` : "Pas encore banni"}
` : ""}
${currentPhase === "completed" ? `
- Draft termin√©, analyse finale de l'√©quipe
- Bans Joueur A: [${playerABans.join(", ")}]
- Bans Joueur B: [${playerBBans.join(", ")}]
- Monstres finaux Joueur A: [${playerAPicks.filter(id => !playerBBans.includes(id)).join(", ")}]
- Monstres finaux Joueur B: [${playerBPicks.filter(id => !playerABans.includes(id)).join(", ")}]
` : ""}
`;

    const prompt = `${AIAssistantInstructions}

${draftContext}

Analyse la situation actuelle et donne des recommandations strat√©giques :
- Si en phase de picking : quels monstres recommandes-tu pour le prochain pick ? Pourquoi ?
- Si en phase de banning : quel monstre recommandes-tu de bannir ? Pourquoi ?
- Analyse les synergies, contre-picks, et win conditions
- Donne des conseils concrets et actionnables

R√©ponds en fran√ßais, de mani√®re concise mais d√©taill√©e.`;

    // TODO: Int√©grer avec votre LLM pr√©f√©r√© (OpenAI, Anthropic, etc.)
    // Pour l'instant, on retourne une r√©ponse placeholder
    const recommendation = await getLLMRecommendation(prompt);

    return NextResponse.json({
      recommendation,
      timestamp: new Date().toISOString(),
    });
  } catch (error) {
    console.error("Erreur lors de la g√©n√©ration de recommandation:", error);
    return NextResponse.json(
      { error: "Erreur lors de la g√©n√©ration de recommandation" },
      { status: 500 }
    );
  }
}

/**
 * Fonction placeholder pour int√©grer avec un LLM
 * √Ä remplacer par l'int√©gration r√©elle (OpenAI, Anthropic, etc.)
 */
async function getLLMRecommendation(prompt: string): Promise<string> {
  // TODO: Int√©grer avec votre API LLM
  // Exemple avec OpenAI :
  /*
  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${process.env.OPENAI_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: "gpt-4",
      messages: [
        { role: "system", content: AIAssistantInstructions },
        { role: "user", content: prompt },
      ],
      temperature: 0.7,
      max_tokens: 1000,
    }),
  });

  const data = await response.json();
  return data.choices[0].message.content;
  */

  // Placeholder pour le d√©veloppement
  return `
Recommandation IA (Mode D√©veloppement)

üìä Analyse du draft actuel :
- Vous avez ${prompt.includes("Picks Joueur A") ? "X" : "0"} monstres
- L'adversaire a ${prompt.includes("Picks Joueur B") ? "X" : "0"} monstres

üí° Recommandations :
1. Analysez les synergies entre vos monstres actuels
2. Identifiez les contre-picks potentiels de l'adversaire
3. Pensez aux win conditions possibles
4. Anticipez les bans probables

‚ö†Ô∏è Note : Cette fonctionnalit√© n√©cessite l'int√©gration avec un service LLM (OpenAI, Anthropic, etc.)
Consultez le fichier app/api/draft/recommend/route.ts pour l'impl√©mentation.
  `.trim();
}

